{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_mining.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-osQdakss_FE",
        "n5mHYgDbtFT7",
        "zuNzNeTIvE6f",
        "VrVIajpOIRI1",
        "tSZR6VL1H3db",
        "6Ogh6GzpSwkU",
        "gbs-n4Nl8CVG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXKAsqnNhUrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1 = 'ethics are built right into the ideals and objectives of United'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAS3ZTLRsrfp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-osQdakss_FE",
        "colab_type": "text"
      },
      "source": [
        "# Basic Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw016Ouohkjn",
        "colab_type": "code",
        "outputId": "2e9a6ee3-414d-4e0a-fa4e-1217e4c5eded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(text1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siQcwzE6hqjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2 = text1.split(' ')\n",
        "#.splitlines()\n",
        "#.join(t)  opposite of splitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63AzdS7Eh3XZ",
        "colab_type": "code",
        "outputId": "2a0e7933-af92-46cf-f0f4-0f4b80d6e58f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(text2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZn4dw7gh51Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndNt5sxhh75B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to find text that is >3 letter long\n",
        "[w for w in text2 if len(w) > 3 ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8t0IN7AiV7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check if word starts with capital letter\n",
        "[w for w in text2 if w.istitle()]\n",
        "#isupper()\n",
        "#islower()\n",
        "#isalpha\n",
        "#isdigit\n",
        "#isalnum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADp0lOHDikwS",
        "colab_type": "code",
        "outputId": "4f0fcecd-16c1-43a8-9c45-7dd113865619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#to check if the word ends with 's'\n",
        "[w for w in text2 if w.endswith('s')]\n",
        "\n",
        "#startswith()\n",
        "#t in s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ethics', 'ideals', 'objectives', 'Natons']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8NOF-W4iyna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text3 = 'To be or not to be'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_GJnoNpjRKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text4 = text3.split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD7NeyxdjU_f",
        "colab_type": "code",
        "outputId": "c4fa314c-8a01-45da-958c-aefdb5964e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(set(text4)) # but only 4 unique to be or not"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGbFkd69jaht",
        "colab_type": "code",
        "outputId": "076fcd6e-2fe9-4402-db52-d495f1cedb5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(set([w.lower() for w in text4]))\n",
        "#.upper()\n",
        "#.titlecase()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmOr91nAj3vN",
        "colab_type": "code",
        "outputId": "3b9c1f54-2a44-41b0-dd81-cb5e1b21af5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "s.strip() it will remove all the white space characters from the string from the front and end\n",
        "s.rstrip() from the end of the string\n",
        "s.find(t) will give the index\n",
        "s.rfind(t) index from reverse\n",
        "s.replace(u,v) replace every occurence with v\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ns.strip() it will remove all the white space characters from the string from the front\\ns.rstrip() from the end of the string\\ns.find(t)\\ns.rfind(t)\\ns.replace(u,v) replace every occurence with v\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YByO23OjmD8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = 'ouagadouug' # it wont get split because there is not separator so we can use list(t)\n",
        "# or [c for c in t]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA30gjxxmWx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cleaning\n",
        "text8 = '    A quick brown frog jumped over the body.  '\n",
        "# if split by ' ' then empty string will also come\n",
        "text9 =text8.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVeH62Gfmy1V",
        "colab_type": "code",
        "outputId": "bd96470b-b03e-4647-ab9c-504d3694f942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text9.split(' ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'quick', 'brown', 'frog', 'jumped', 'over', 'the', 'body.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-2sO0HMm2B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5mHYgDbtFT7",
        "colab_type": "text"
      },
      "source": [
        "# Larger Files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMqtvJMFtIPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "f = open('file.txt', 'r') in read mode\n",
        "f.readline() read the first line, it will give \\n at the end\n",
        "\n",
        "\n",
        "f.seek(0) reset the reading to 0 \n",
        "text12 = f.read() or f.read(n) to read n characters\n",
        "f.write(message)\n",
        "f.close()\n",
        "text13 = text12.splitlines() delimited by backslash \\n\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuNzNeTIvE6f",
        "colab_type": "text"
      },
      "source": [
        "# Regex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJFfTVhxve-g",
        "colab_type": "code",
        "outputId": "e55a5a45-6155-4207-e864-080cb58d6756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''We can use regular expressions to help us with more complex parsing.\n",
        "\n",
        "For example '@[A-Za-z0-9_]+' will return all words that:\n",
        "\n",
        "start with '@' and are followed by at least one:\n",
        "capital letter ('A-Z')\n",
        "lowercase letter ('a-z')\n",
        "number ('0-9')\n",
        "or underscore ('_')\n",
        "'''\n",
        "\n",
        "#import re # import re - a module that provides support for regular expressions\n",
        "\n",
        "#[w for w in text8 if re.search('@[A-Za-z0-9_]+', w)]\n",
        "\n",
        "# + means for one or more times\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"We can use regular expressions to help us with more complex parsing.\\n\\nFor example '@[A-Za-z0-9_]+' will return all words that:\\n\\nstart with '@' and are followed by at least one:\\ncapital letter ('A-Z')\\nlowercase letter ('a-z')\\nnumber ('0-9')\\nor underscore ('_')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fejQ4GuzgTh",
        "colab_type": "code",
        "outputId": "7b750358-0a57-4875-ff40-78e1340478f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        ".  = wildcard, matches a single character\n",
        "^ = start of a string\n",
        "$ = end of the string\n",
        "[] = mathces one of the set of characters within []\n",
        "[a-z] = matches one of the range of characters\n",
        "[^abc] = not a or b or c\n",
        "a|b = matches a or b, where a and b are strings\n",
        "\\d = any digit\n",
        "\\D = any non digit\n",
        "\\s = any whitespace character\n",
        "\\S = any non white space character\n",
        "\\w = any alphanumeric characteer\n",
        "\\W = .......\n",
        "\n",
        "\n",
        "* = 0 or more times\n",
        "+ = one or more times\n",
        "? = 0 or one\n",
        "{3} = exactly 3\n",
        "{n,} = atleast n\n",
        "{,n} = atmost n\n",
        "{m,n} = atleast m and atmost n\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n.  = wildcard, matches a single character\\n^ = start of a string\\n$ = end of the string\\n[] = mathces one of the set of characters within []\\n[a-z] = matches one of the range of characters\\n[^abc] = not a or b or c\\na|b = matches a or b, where a and b are strings\\n\\\\d = any digit\\n\\\\D = any non digit\\n\\\\s = any whitespace character\\n\\\\S = any non white space character\\n\\\\w = any alphanumeric characteer\\n\\\\W = .......\\n\\n\\n* = 0 or more times\\n+ = one or more times\\n? = 0 or one\\n{3} = exactly 3\\n{n,} = atleast n\\n{,n} = atmost n\\n{m,n} = atleast m and atmost n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf9GSApl1G2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [w for w in text12 if re.search('@\\w+',text12)] it will gives words starting with @ with one or more occurences of alphnumeric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b11hQGXi1evB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#re.findall(r'[aeiou]', text12) # find all vowels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owzItpxr1_i1",
        "colab_type": "code",
        "outputId": "2fab8878-16a6-4284-a2ec-aeb37641e996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# to write date\n",
        "# exp =re.findall( r'\\d{2}[\\-]\\d{2}[\\-]\\d{4}', text12)\n",
        "# r is used to tell that take whole as a raw string\n",
        "\n",
        "# r'\\d{2} (?:jan|feb|march) \\d{4}'\n",
        "'''\n",
        "two digits with a slash or a dash then again for month and then 4 digit for year\n",
        " '''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntwo digits with a slash or a dash then again for month and then 4 digit for year\\n '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP4aSXtk4Mve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8K6Couw_TGk",
        "colab_type": "code",
        "outputId": "008db460-422d-4b29-9106-5fde242bf76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "time_sentences = [\"Monday: The doctor's appointment is at 2:45pm.\", \n",
        "                  \"Tuesday: The dentist's appointment is at 11:30 am.\",\n",
        "                  \"Wednesday: At 7:00pm, there is a basketball game!\",\n",
        "                  \"Thursday: Be back home by 11:15 pm at the latest.\",\n",
        "                  \"Friday: Take the train at 08:10 am, arrive at 09:00am.\"]\n",
        "\n",
        "df = pd.DataFrame(time_sentences, columns=['text'])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Monday: The doctor's appointment is at 2:45pm.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tuesday: The dentist's appointment is at 11:30...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wednesday: At 7:00pm, there is a basketball game!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thursday: Be back home by 11:15 pm at the latest.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Friday: Take the train at 08:10 am, arrive at ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0     Monday: The doctor's appointment is at 2:45pm.\n",
              "1  Tuesday: The dentist's appointment is at 11:30...\n",
              "2  Wednesday: At 7:00pm, there is a basketball game!\n",
              "3  Thursday: Be back home by 11:15 pm at the latest.\n",
              "4  Friday: Take the train at 08:10 am, arrive at ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mHGO75l_W_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the number of characters for each string in df['text']\n",
        "df['text'].str.len()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0WPTT4-ApDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the number of tokens for each string in df['text']\n",
        "df['text'].str.split().str.len()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPE8-mQ8Ay2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find which entries contain the word 'appointment'\n",
        "df['text'].str.contains('appointment')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgYubnLCA5d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find how many times a digit occurs in each string\n",
        "df['text'].str.count(r'\\d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz-EXZowBBTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find all occurances of the digits\n",
        "df['text'].str.findall(r'\\d')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYqM5OYQBOqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# group and find the hours and minutes\n",
        "df['text'].str.findall(r'(\\d?\\d):(\\d\\d)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWzKDs85CArh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create new columns from first match of extracted groups\n",
        "df['text'].str.extract(r'(\\d?\\d):(\\d\\d)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX2O76zACB-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the entire time, the hours, the minutes, and the period\n",
        "df['text'].str.extractall(r'((\\d?\\d):(\\d\\d) ?([ap]m))')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoRqRh-sCO2u",
        "colab_type": "code",
        "outputId": "c9bfb4f2-81c9-4950-ba4c-2a379c239e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# extract the entire time, the hours, the minutes, and the period with group names\n",
        "df['text'].str.extractall(r'(?P<time>(?P<hour>\\d?\\d):(?P<minute>\\d\\d) ?(?P<period>[ap]m))')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>period</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>match</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <td>2:45pm</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "      <td>pm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <th>0</th>\n",
              "      <td>11:30 am</td>\n",
              "      <td>11</td>\n",
              "      <td>30</td>\n",
              "      <td>am</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <th>0</th>\n",
              "      <td>7:00pm</td>\n",
              "      <td>7</td>\n",
              "      <td>00</td>\n",
              "      <td>pm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <th>0</th>\n",
              "      <td>11:15 pm</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>pm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
              "      <th>0</th>\n",
              "      <td>08:10 am</td>\n",
              "      <td>08</td>\n",
              "      <td>10</td>\n",
              "      <td>am</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09:00am</td>\n",
              "      <td>09</td>\n",
              "      <td>00</td>\n",
              "      <td>am</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             time hour minute period\n",
              "  match                             \n",
              "0 0        2:45pm    2     45     pm\n",
              "1 0      11:30 am   11     30     am\n",
              "2 0        7:00pm    7     00     pm\n",
              "3 0      11:15 pm   11     15     pm\n",
              "4 0      08:10 am   08     10     am\n",
              "  1       09:00am   09     00     am"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fysb4VbgCZsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrVIajpOIRI1",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AanXBRI8N7t",
        "colab_type": "text"
      },
      "source": [
        "Extract all the dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtY3KuUyBUL6",
        "colab_type": "code",
        "outputId": "f98565e5-bc48-40f4-c652-450129d68d45",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f437a202-7b56-4f9c-b105-83591011adea\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f437a202-7b56-4f9c-b105-83591011adea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dates.txt to dates.txt\n",
            "User uploaded file \"dates.txt\" with length 67938 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scnh4S3rBU6g",
        "colab_type": "code",
        "outputId": "41d09372-6f38-4bc6-94b0-e38e3b0cfbcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "doc = []\n",
        "with open('dates.txt') as file:\n",
        "    for line in file:\n",
        "        doc.append(line)\n",
        "\n",
        "df = pd.Series(doc)\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         03/25/93 Total time of visit (in minutes):\\n\n",
              "1                       6/18/85 Primary Care Doctor:\\n\n",
              "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
              "3                7 on 9/27/75 Audit C Score Current:\\n\n",
              "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
              "5                    .Per 7/06/79 Movement D/O note:\\n\n",
              "6    4, 5/18/78 Patient's thoughts about current su...\n",
              "7    10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
              "8                         3/7/86 SOS-10 Total Score:\\n\n",
              "9             (4/10/71)Score-1Audit C Score Current:\\n\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfhRumNNBhpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def date_sorter():\n",
        "    \n",
        "    regex1 = '(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})'\n",
        "    regex2 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[+\\s]\\d{1,2}[,]{0,1}[+\\s]\\d{4})'\n",
        "    regex3 = '(\\d{1,2}[+\\s](?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[+\\s]\\d{4})'\n",
        "    regex4 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[+\\s]\\d{4})'\n",
        "    regex5 = '(\\d{1,2}[/-][1|2]\\d{3})'\n",
        "    regex6 = '([1|2]\\d{3})'\n",
        "    full_regex = '(%s|%s|%s|%s|%s|%s)' %(regex1, regex2, regex3, regex4, regex5, regex6)\n",
        "    parsed_date = df.str.extract(full_regex)\n",
        "    parsed_date = parsed_date.iloc[:,0].str.replace('Janaury', 'January').str.replace('Decemeber', 'December')\n",
        "    parsed_date = pd.Series(pd.to_datetime(parsed_date))\n",
        "    parsed_date = parsed_date.sort_values(ascending=True).index\n",
        "    return pd.Series(parsed_date.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlEwp50VB6q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSZR6VL1H3db",
        "colab_type": "text"
      },
      "source": [
        "# NLTK Basic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onumK0DwH5ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaGihSTKIK-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_zou4iIqS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('treebank')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('inaugural')\n",
        "#nltk.download('all')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyew9HfnH7Nj",
        "colab_type": "code",
        "outputId": "4e6e73d5-d0f0-4590-c2b8-75295166057c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "from nltk.book import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsfywYAQJD2V",
        "colab_type": "code",
        "outputId": "0fe75dff-9497-475f-a3b5-4022d99cdfc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Moby Dick by Herman Melville 1851>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7yn6cjQJsBQ",
        "colab_type": "code",
        "outputId": "5f59d34c-0032-4ce9-f6a2-20280526988f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "sents() # one sentence each from each text corpora"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sent1: Call me Ishmael .\n",
            "sent2: The family of Dashwood had long been settled in Sussex .\n",
            "sent3: In the beginning God created the heaven and the earth .\n",
            "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
            "sent5: I have a problem with people PMing me to lol JOIN\n",
            "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
            "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
            "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
            "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OffeOkj0JxdO",
        "colab_type": "code",
        "outputId": "c8aa138f-e667-47e9-8c6e-a8305f29e4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sent1 # first sentence from text1 into list form"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Call', 'me', 'Ishmael', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4sStLlXKF8v",
        "colab_type": "code",
        "outputId": "2dc659c6-8af3-4b40-f636-5856c48b9186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "sent7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pierre',\n",
              " 'Vinken',\n",
              " ',',\n",
              " '61',\n",
              " 'years',\n",
              " 'old',\n",
              " ',',\n",
              " 'will',\n",
              " 'join',\n",
              " 'the',\n",
              " 'board',\n",
              " 'as',\n",
              " 'a',\n",
              " 'nonexecutive',\n",
              " 'director',\n",
              " 'Nov.',\n",
              " '29',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgxvDT6hKqEd",
        "colab_type": "code",
        "outputId": "0fb97c61-1867-4908-9939-05205336c3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(sent7) # may not be unique"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztYBij11KvAK",
        "colab_type": "code",
        "outputId": "c53d6c14-d74e-4dd5-bab1-ce6a13365fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(text7) # total words may not be unique"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBQ-wWsGKw96",
        "colab_type": "code",
        "outputId": "bde7d73b-970c-4c19-d9b3-3976e281502d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(set(text7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI3x9zWYK8IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list(text7) # all the words in the text7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvLdBh9hLQ4t",
        "colab_type": "code",
        "outputId": "08b588bd-e08a-4720-d94f-c52ccb745453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "list(set(text7))[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['allegedly',\n",
              " '*-72',\n",
              " 'completed',\n",
              " 'gilt',\n",
              " 'Property\\\\/casualty',\n",
              " 'reforms',\n",
              " 'Huber',\n",
              " 'leap',\n",
              " 'FTC',\n",
              " 'crapshoot']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOqx1xr9Obch",
        "colab_type": "text"
      },
      "source": [
        "Freq of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oppu49XoLbOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# frequency of words\n",
        "d = FreqDist(text7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3AtpSTFL3dY",
        "colab_type": "code",
        "outputId": "d849248d-1ead-4d4c-da50-d9d45b25a405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX1_d12hL4aN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_words = list(d.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bBwm1cDMDXK",
        "colab_type": "code",
        "outputId": "23282abb-8376-43b5-dced-6d17dd4e47fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_words[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pierre', 'Vinken', ',', '61', 'years', 'old', 'will', 'join', 'the', 'board']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zK08Yb_MGiK",
        "colab_type": "code",
        "outputId": "aab3d4e9-6233-4506-83ee-dba5e8d03128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "d[',']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KMKyDEjMwEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq_words = [w for w in vocab_words if len(w) > 5 and d[w] > 100] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spHSlf8lNJIt",
        "colab_type": "code",
        "outputId": "fe3105fd-38f1-4a07-fc14-83c23c6ee6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "freq_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['billion',\n",
              " 'company',\n",
              " 'president',\n",
              " 'because',\n",
              " 'market',\n",
              " 'million',\n",
              " 'shares',\n",
              " 'trading',\n",
              " 'program']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN-nB8ttOUtI",
        "colab_type": "text"
      },
      "source": [
        "**Normalising and stemming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2D8w1VFOoOz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*  Normalisation is when we transform the words to make it appear the same way say play, played, Play, playing etc\n",
        "*   Stemming is to find the root word\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQW0LDnbO8Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = 'play played Play plays playing playings'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J48HVxvpPF6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word = t.lower().split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKJsY-qjPL5w",
        "colab_type": "code",
        "outputId": "841a5cd9-3401-4bfc-bc03-9db00f5a0c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['play', 'played', 'play', 'plays', 'playing', 'playings']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1JeKeRvPPpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "porter = nltk.PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp5l9NSKPwtD",
        "colab_type": "code",
        "outputId": "c86ab4ae-64b1-41d8-b5f0-02202ec0da19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[porter.stem(w) for w in word] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['play', 'play', 'play', 'play', 'play', 'play']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R77qkihQNnh",
        "colab_type": "text"
      },
      "source": [
        "Lemmatisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FazYWTurP0fP",
        "colab_type": "code",
        "outputId": "91820875-cfc6-44a8-d505-f098c17b9217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nltk.download('udhr')\n",
        "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
        "# universal declaration of human rights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/udhr.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWsJ4Cv5QbWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "udhr[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrOL1IUFQub7",
        "colab_type": "code",
        "outputId": "3e7bac15-11f4-4f69-e74a-ecac3a684355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "[porter.stem(w) for w in udhr[:20]]  # here we can say that some words are not valid so lemmatization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['univers',\n",
              " 'declar',\n",
              " 'of',\n",
              " 'human',\n",
              " 'right',\n",
              " 'preambl',\n",
              " 'wherea',\n",
              " 'recognit',\n",
              " 'of',\n",
              " 'the',\n",
              " 'inher',\n",
              " 'digniti',\n",
              " 'and',\n",
              " 'of',\n",
              " 'the',\n",
              " 'equal',\n",
              " 'and',\n",
              " 'inalien',\n",
              " 'right',\n",
              " 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugHIb7blQ49i",
        "colab_type": "code",
        "outputId": "4f2fc3ec-0813-417e-9461-63d13b1af327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "WNlemma = nltk.WordNetLemmatizer()\n",
        "[WNlemma.lemmatize(t) for t in udhr[:20]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Universal',\n",
              " 'Declaration',\n",
              " 'of',\n",
              " 'Human',\n",
              " 'Rights',\n",
              " 'Preamble',\n",
              " 'Whereas',\n",
              " 'recognition',\n",
              " 'of',\n",
              " 'the',\n",
              " 'inherent',\n",
              " 'dignity',\n",
              " 'and',\n",
              " 'of',\n",
              " 'the',\n",
              " 'equal',\n",
              " 'and',\n",
              " 'inalienable',\n",
              " 'right',\n",
              " 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68EEctxLRgTd",
        "colab_type": "text"
      },
      "source": [
        "Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKAxt2cmRJvk",
        "colab_type": "code",
        "outputId": "9fc56917-f2dc-4519-e3be-99d69bcd248a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "text11 = \"Children shouldn't drink a sugary drink before bed.\"\n",
        "text11.split(' ') # it is also keeping full stop so we can use inbuilt tokeniser"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Children', \"shouldn't\", 'drink', 'a', 'sugary', 'drink', 'before', 'bed.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWqcApIXRkH5",
        "colab_type": "code",
        "outputId": "6fc1eeac-8b6d-4f9f-a5bd-db6db2215632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "nltk.word_tokenize(text11)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Children',\n",
              " 'should',\n",
              " \"n't\",\n",
              " 'drink',\n",
              " 'a',\n",
              " 'sugary',\n",
              " 'drink',\n",
              " 'before',\n",
              " 'bed',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBZVGAsjR8Dq",
        "colab_type": "code",
        "outputId": "5e4fea53-8b6f-43c1-c1a2-b4d9b12d33ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text12 = \"This is the first sentence. A gallon of milk in the U.S. costs $2.99. Is this the third sentence? Yes, it is!\"\n",
        "sentences = nltk.sent_tokenize(text12) # nltk inbuilt sentence splitter\n",
        "len(sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocg28-UnSXT2",
        "colab_type": "code",
        "outputId": "57111501-e424-4d7b-99ff-e79790c44086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This is the first sentence.',\n",
              " 'A gallon of milk in the U.S. costs $2.99.',\n",
              " 'Is this the third sentence?',\n",
              " 'Yes, it is!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyKfHpTXSZbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ogh6GzpSwkU",
        "colab_type": "text"
      },
      "source": [
        "# NLTK Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3qMre8sWMpw",
        "colab_type": "text"
      },
      "source": [
        "POS(Part of speech) tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFpMAd0TSzi7",
        "colab_type": "code",
        "outputId": "437525a7-ad99-4e2d-f4a7-d8b1ae7fbec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('tagsets')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLhwQ_nUWgiG",
        "colab_type": "code",
        "outputId": "37b52457-ae4d-466e-ed55-2a3a78fc47b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.help.upenn_tagset('MD')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2IXIkwTWnYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text11 = \"Children shouldn't drink a sugary drink before bed.\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYE5E0AbW5w5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text13 = nltk.word_tokenize(text11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHFdLvE_W6Ed",
        "colab_type": "code",
        "outputId": "a7b6711f-8813-4743-b41c-c6d7b347ba0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.pos_tag(text13)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Children', 'NNP'),\n",
              " ('should', 'MD'),\n",
              " (\"n't\", 'RB'),\n",
              " ('drink', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('sugary', 'JJ'),\n",
              " ('drink', 'NN'),\n",
              " ('before', 'IN'),\n",
              " ('bed', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-ytO9_vXCje",
        "colab_type": "code",
        "outputId": "ffe61875-2ff7-4817-daa0-88e406c952c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "# Parsing sentence structure\n",
        "text15 = nltk.word_tokenize(\"Alice loves Bob\")\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "VP -> V NP\n",
        "NP -> 'Alice' | 'Bob'\n",
        "V -> 'loves'\n",
        "\"\"\")\n",
        "\n",
        "parser = nltk.ChartParser(grammar)\n",
        "trees = parser.parse_all(text15)\n",
        "for tree in trees:\n",
        "    print(tree)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "(S (NP Alice) (VP (V loves) (NP Bob)))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo8N290u5uB0",
        "colab_type": "code",
        "outputId": "f7749699-f126-4d2f-8cc2-9545c0f738c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# generating grammer rules is very time consuming task\n",
        "nltk.download('treebank')\n",
        "from nltk.corpus import treebank\n",
        "text17 = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
        "print(text17)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "(S\n",
            "  (NP-SBJ\n",
            "    (NP (NNP Pierre) (NNP Vinken))\n",
            "    (, ,)\n",
            "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
            "    (, ,))\n",
            "  (VP\n",
            "    (MD will)\n",
            "    (VP\n",
            "      (VB join)\n",
            "      (NP (DT the) (NN board))\n",
            "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
            "      (NP-TMP (NNP Nov.) (CD 29))))\n",
            "  (. .))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv5fai7t7KVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbs-n4Nl8CVG",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x-lb5c08ENZ",
        "colab_type": "code",
        "outputId": "521dd446-b806-4bdb-de93-f2ec534bd9d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# ratio of whale and Whale count by total freq of words\n",
        "'''\n",
        "def answer_two():\n",
        "    \n",
        "    dist = nltk.FreqDist(text1)\n",
        "    return (dist['whale'] + dist['Whale'])/len(text1)*100\n",
        "\n",
        "answer_two()\n",
        "\n",
        "\n",
        "'''\n",
        "# most common 20 words\n",
        "#return nltk.FreqDist(text1).most_common(20)\n",
        "\n",
        "'''\n",
        "#length of greater than 5 and frequency of more than 150?\n",
        "    dist = nltk.FreqDist(text1)\n",
        "    vocab1 = dist.keys()\n",
        "    freqwords = [w for w in vocab1 if len(w)>5 and dist[w] > 150]\n",
        "    return sorted(freqwords)\n",
        "'''\n",
        "\n",
        "'''\n",
        "#longest word in text1 and that word's length.\n",
        "\n",
        "    maxlen = max(len(w) for w in text1)\n",
        "    word = [w for w in text1 if len(w) == maxlen]\n",
        "    return (word[0],maxlen)\n",
        "'''\n",
        "\n",
        "#unique words have a frequency of more than 2000? What is their frequency?\n",
        "'''\n",
        "    dist = nltk.FreqDist(text1)\n",
        "    freqwords = [(dist[w],w) for w in set(text1) if w.isalpha() and dist[w]>2000]\n",
        "    return sorted(freqwords, key=lambda x:x[0],reverse=True)\n",
        "\n",
        "'''\n",
        "\n",
        "#What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
        "'''\n",
        "    import collections\n",
        "    pos_list = nltk.pos_tag(text1)\n",
        "    pos_counts = collections.Counter((subl[1] for subl in pos_list))\n",
        "    return pos_counts.most_common(5)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    import collections\\n    pos_list = nltk.pos_tag(text1)\\n    pos_counts = collections.Counter((subl[1] for subl in pos_list))\\n    return pos_counts.most_common(5)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyM51nLe8ZgA",
        "colab_type": "code",
        "outputId": "63aac3ba-3786-4458-b6e0-71f651a46d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#spelling recommendation\n",
        "\n",
        "'''\n",
        "\n",
        "from nltk.corpus import words\n",
        "correct_spellings = words.words()\n",
        "\n",
        "#For every misspelled word, the recommender should find find the word in correct_spellings that has the shortest distance*, \n",
        "#and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
        "\n",
        "#*Each of the three different recommenders will use a different distance measure\n",
        "\n",
        "\n",
        "def answer(entries=['cormulent', 'incendenece', 'validrate']):\n",
        "    \n",
        "    recommend = []\n",
        "    for entry in entries:\n",
        "        \n",
        "        # Match first letter. input_spell contains all words in correct_spellings with the same first letter.\n",
        "        input_spell = [x for x in correct_spellings if x[0] == entry[0]]\n",
        "        \n",
        "        # Find the jaccard distance between the entry word and every word in correct_spellings with the same first letter.\n",
        "        jaccard_dist = [nltk.jaccard_distance(set(nltk.ngrams(entry,n=3)), set(nltk.ngrams(x,n=3))) for x in input_spell]\n",
        "        \n",
        "        # Recommend the word in input_spell with the minimum Jaccard distance.\n",
        "        recommend.append(input_spell[np.argmin(jaccard_dist)])\n",
        "        \n",
        "    return recommend\n",
        "\n",
        "'''\n",
        "'''\n",
        "\n",
        "    recommend = []\n",
        "    for entry in entries:\n",
        "        \n",
        "        # Match first letter. input_spell contains all words in correct_spellings with the same first letter.\n",
        "        input_spell = [x for x in correct_spellings if x[0] == entry[0]]\n",
        "        \n",
        "        # Find the edit between the entry word and every word in correct_spellings with the same first letter.\n",
        "        DL_dist = [nltk.edit_distance(x, entry, transpositions=True) for x in input_spell]\n",
        "        \n",
        "        # Recommend the word in input_spell with the minimum edit.\n",
        "        recommend.append(input_spell[np.argmin(DL_dist)])\n",
        "        \n",
        "    return recommend\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n    recommend = []\\n    for entry in entries:\\n        \\n        # Match first letter. input_spell contains all words in correct_spellings with the same first letter.\\n        input_spell = [x for x in correct_spellings if x[0] == entry[0]]\\n        \\n        # Find the edit between the entry word and every word in correct_spellings with the same first letter.\\n        DL_dist = [nltk.edit_distance(x, entry, transpositions=True) for x in input_spell]\\n        \\n        # Recommend the word in input_spell with the minimum edit.\\n        recommend.append(input_spell[np.argmin(DL_dist)])\\n        \\n    return recommend\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXFpTwY1EkmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WowgdYBcy7f_",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDoDvgtiy9co",
        "colab_type": "code",
        "outputId": "7dc29381-d30f-478d-c6ad-b11be527e45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "classifier = NaiveBayesClassifier.train(train_data)\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom nltk.classify import NaiveBayesClassifier\\nclassifier = NaiveBayesClassifier.train(train_data)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_RbRvDi3EaB",
        "colab_type": "code",
        "outputId": "78ade152-0928-4e62-e397-782ba6b57172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_BrQ4k33F_I",
        "colab_type": "code",
        "outputId": "a2e00ab7-9141-47f9-f1ce-13d1c9725c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read in the data\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "# Sample the data to speed up computation\n",
        "# Comment out this line to match with lecture\n",
        "df = df.sample(frac=0.1, random_state=10)\n",
        "\n",
        "df.head()\n",
        "\n",
        "#=========================================\n",
        "#preprocessing\n",
        "\n",
        "# Drop missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove any 'neutral' ratings equal to 3\n",
        "df = df[df['Rating'] != 3]\n",
        "\n",
        "# Encode 4s and 5s as 1 (rated positively)\n",
        "# Encode 1s and 2s as 0 (rated poorly)\n",
        "df['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\n",
        "df.head(10)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nimport pandas as pd\\nimport numpy as np\\n\\n# Read in the data\\ndf = pd.read_csv('Amazon_Unlocked_Mobile.csv')\\n\\n# Sample the data to speed up computation\\n# Comment out this line to match with lecture\\ndf = df.sample(frac=0.1, random_state=10)\\n\\ndf.head()\\n\\n#=========================================\\n#preprocessing\\n\\n# Drop missing values\\ndf.dropna(inplace=True)\\n\\n# Remove any 'neutral' ratings equal to 3\\ndf = df[df['Rating'] != 3]\\n\\n# Encode 4s and 5s as 1 (rated positively)\\n# Encode 1s and 2s as 0 (rated poorly)\\ndf['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\\ndf.head(10)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FoTmDsa5j0o",
        "colab_type": "code",
        "outputId": "49033fec-2dd7-45f6-e64a-01aeae34235d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "# Most ratings are positive\n",
        "df['Positively Rated'].mean()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Most ratings are positive\\ndf['Positively Rated'].mean()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY5yp-Nq5nO8",
        "colab_type": "code",
        "outputId": "15236283-3eb5-4fc5-d6f8-f1eff9653de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], \n",
        "                                                    df['Positively Rated'], \n",
        "                                                    random_state=0)\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.model_selection import train_test_split\\n\\n# Split data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(df['Reviews'], \\n                                                    df['Positively Rated'], \\n                                                    random_state=0)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRhnutuy5rEH",
        "colab_type": "code",
        "outputId": "162a295e-5ff2-4d14-dafd-0a14649636b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
        "print('\\n\\nX_train shape: ', X_train.shape)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint('X_train first entry:\\n\\n', X_train.iloc[0])\\nprint('\\n\\nX_train shape: ', X_train.shape)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dAdQeHA5vBS",
        "colab_type": "code",
        "outputId": "d830d870-47c8-42fc-ec84-15f6a6a461ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#####CountVectorizer\n",
        "'''\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Fit the CountVectorizer to the training data\n",
        "vect = CountVectorizer().fit(X_train)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.feature_extraction.text import CountVectorizer\\n\\n# Fit the CountVectorizer to the training data\\nvect = CountVectorizer().fit(X_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn4CSwPr65pj",
        "colab_type": "code",
        "outputId": "10603eae-e674-49a6-96d3-be5797a55ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "vect.get_feature_names()[::2000]\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nvect.get_feature_names()[::2000]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GBiaag77UuO",
        "colab_type": "code",
        "outputId": "e7d66a83-1d1b-4907-85e0-1207891f3029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "len(vect.get_feature_names())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlen(vect.get_feature_names())\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnLXFGdW7WEz",
        "colab_type": "code",
        "outputId": "b30cc097-bb6a-4847-9b8f-0e79ea0c0868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "# transform the documents in the training data to a document-term matrix\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "\n",
        "X_train_vectorized\n",
        "'''\n",
        "# each row is a document and each column is a word of the vocabulary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# transform the documents in the training data to a document-term matrix\\nX_train_vectorized = vect.transform(X_train)\\n\\nX_train_vectorized\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5WicLLO7qPb",
        "colab_type": "code",
        "outputId": "159a4cfd-3a43-4af7-c652-4fbf834cd505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# training\n",
        "'''\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "'''\n",
        "# Logistics regression works for high dimensional sparse data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.linear_model import LogisticRegression\\n\\n# Train the model\\nmodel = LogisticRegression()\\nmodel.fit(X_train_vectorized, y_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weZ8nCTh8GpH",
        "colab_type": "code",
        "outputId": "f7b684f5-d4b6-46da-e666-23a8a8818417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# predict\n",
        "'''\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Predict the transformed test documents\n",
        "predictions = model.predict(vect.transform(X_test))\n",
        "\n",
        "print('AUC: ', roc_auc_score(y_test, predictions))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.metrics import roc_auc_score\\n\\n# Predict the transformed test documents\\npredictions = model.predict(vect.transform(X_test))\\n\\nprint('AUC: ', roc_auc_score(y_test, predictions))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvohwsSx8L3y",
        "colab_type": "code",
        "outputId": "4840d19f-4c49-4608-aa4d-f6d61ee23d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "# get the feature names as numpy array\n",
        "feature_names = np.array(vect.get_feature_names())\n",
        "\n",
        "# Sort the coefficients from the model\n",
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "\n",
        "# Find the 10 smallest and 10 largest coefficients\n",
        "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
        "# so the list returned is in order of largest to smallest\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# get the feature names as numpy array\\nfeature_names = np.array(vect.get_feature_names())\\n\\n# Sort the coefficients from the model\\nsorted_coef_index = model.coef_[0].argsort()\\n\\n# Find the 10 smallest and 10 largest coefficients\\n# The 10 largest coefficients are being indexed using [:-11:-1] \\n# so the list returned is in order of largest to smallest\\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzklSFKz8nNH",
        "colab_type": "code",
        "outputId": "ca01c446-1cda-48fc-b224-b1e14ea28267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Tfidf term frequency inverse documnet frequency\n",
        "# it allows us to weight terms based on how imp they are to the document\n",
        "'''\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
        "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
        "len(vect.get_feature_names())\n",
        "'''\n",
        "#will give same number of features as we got earlier\n",
        "#min_df = 5 means the tfidf will remove those words that appear in fewer than 5 documents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\n# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\\nvect = TfidfVectorizer(min_df=5).fit(X_train)\\nlen(vect.get_feature_names())\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIVMtDKe84pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# features with high weight appear often in a particular document but not so often in corpus\n",
        "# features with low tfidf are either used commonly across all the documents or rarely  in long documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjdV4Yvi97lm",
        "colab_type": "code",
        "outputId": "3e425e9c-6632-4a81-82a2-2c2110cbf6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(vect.transform(X_test))\n",
        "\n",
        "print('AUC: ', roc_auc_score(y_test, predictions))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nX_train_vectorized = vect.transform(X_train)\\n\\nmodel = LogisticRegression()\\nmodel.fit(X_train_vectorized, y_train)\\n\\npredictions = model.predict(vect.transform(X_test))\\n\\nprint('AUC: ', roc_auc_score(y_test, predictions))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSl7j4C4-Sxy",
        "colab_type": "code",
        "outputId": "50a8969f-ce23-41bd-e84c-e3453ab42462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "feature_names = np.array(vect.get_feature_names())\n",
        "\n",
        "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
        "\n",
        "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
        "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfeature_names = np.array(vect.get_feature_names())\\n\\nsorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\\n\\nprint('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL4FIc5E-Z73",
        "colab_type": "code",
        "outputId": "e2ec405a-e40a-472e-ac06-52c9b4d8f96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nsorted_coef_index = model.coef_[0].argsort()\\n\\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvSkbWuc-ts7",
        "colab_type": "code",
        "outputId": "d7142d5e-726b-4723-df80-3a521e3ea2c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "# These reviews are treated the same by our current model\n",
        "print(model.predict(vect.transform(['not an issue, phone is working',\n",
        "                                    'an issue, phone is not working'])))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# These reviews are treated the same by our current model\\nprint(model.predict(vect.transform(['not an issue, phone is working',\\n                                    'an issue, phone is not working'])))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g9Cpuv_-7B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#n-grams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2T7hN8P_AOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we can add context by adding sequences of word features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33rZvUXw_Igj",
        "colab_type": "code",
        "outputId": "545de1a9-e39b-435e-b6f6-2ac6a9098c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "# Fit the CountVectorizer to the training data specifiying a minimum \n",
        "# document frequency of 5 and extracting 1-grams and 2-grams\n",
        "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
        "\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "\n",
        "len(vect.get_feature_names())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Fit the CountVectorizer to the training data specifiying a minimum \\n# document frequency of 5 and extracting 1-grams and 2-grams\\nvect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\\n\\nX_train_vectorized = vect.transform(X_train)\\n\\nlen(vect.get_feature_names())\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUfBV4Ej_V3n",
        "colab_type": "code",
        "outputId": "f631af6e-7164-4ee3-c8ce-30c349eff234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(vect.transform(X_test))\n",
        "\n",
        "print('AUC: ', roc_auc_score(y_test, predictions))'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel = LogisticRegression()\\nmodel.fit(X_train_vectorized, y_train)\\n\\npredictions = model.predict(vect.transform(X_test))\\n\\nprint('AUC: ', roc_auc_score(y_test, predictions))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NfW37EY_ZPC",
        "colab_type": "code",
        "outputId": "c6a620bd-4ea3-437b-ac75-865369d097bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "feature_names = np.array(vect.get_feature_names())\n",
        "\n",
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfeature_names = np.array(vect.get_feature_names())\\n\\nsorted_coef_index = model.coef_[0].argsort()\\n\\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsRBUfOw_cZS",
        "colab_type": "code",
        "outputId": "1976b189-aabd-4fcc-af69-338e7a3abf77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "# These reviews are now correctly identified\n",
        "print(model.predict(vect.transform(['not an issue, phone is working',\n",
        "                                    'an issue, phone is not working'])))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# These reviews are now correctly identified\\nprint(model.predict(vect.transform(['not an issue, phone is working',\\n                                    'an issue, phone is not working'])))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyPI1W8K_gZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AhMdMgRQWDW",
        "colab_type": "text"
      },
      "source": [
        "# Text Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdCR-W7qQZUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqDyktnRS6R",
        "colab_type": "code",
        "outputId": "438f31a4-ac15-42fa-cb6e-c56ab87d9b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPtcmdwrQkQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding appropriate sense of words\n",
        "deer = wn.synset('deer.n.01') # sysnet of deer which is a noun and gives the 1st synset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMBokbFhRO8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to find path similarity\n",
        "#deer.path_similarity(horse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdeHtNOoRYyW",
        "colab_type": "code",
        "outputId": "2a838d9b-4225-4a6a-9c48-d7d2f691f611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# to find lin similarity\n",
        "nltk.download('wordnet_ic')\n",
        "from nltk.corpus import wordnet_ic\n",
        "brown_ic = wordnet_ic.ic('ic-brown.dat')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjHtqVjMSkUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deer.lin_similarity(elk, brown_ic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtaKio0bSulA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.collocations import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPbifK9vWCCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(text)\n",
        "finder.nbest(bigram_measures.pmi, 10)\n",
        "#finder.apply_freq_filter(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTkgOJSMcrxG",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biHLyNxjcuJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}